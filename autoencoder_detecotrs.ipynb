{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder_detecotrs.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-nqaRk_lT0ZE",
        "HyUzlPS9TrHk",
        "1xz4LxO3il2r",
        "-AZCJMlgpVGr",
        "upTUUeN-YCW1",
        "ZfF9bqvkpiST",
        "qyZCOzOQMKlB",
        "TR7H7QmnNa6B",
        "SsYNPXdzfDEm",
        "brOupfLbWyQ6",
        "5N7etXQRS2t_",
        "owt-h0usSrUE",
        "-fdyVIf7hiDW",
        "EemFGYo6BbPB",
        "QX8PF58jBztd"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nqaRk_lT0ZE"
      },
      "source": [
        "## Imports and libraries installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDaKuzLJY96E"
      },
      "source": [
        "%%capture\n",
        "import os\n",
        "import cv2 \n",
        "import ast\n",
        "import time\n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# install libraries\n",
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "!pip install -U git+https://github.com/qubvel/segmentation_models.pytorch\n",
        "import segmentation_models_pytorch as smp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb3Lv-VbvpEq"
      },
      "source": [
        "## Install custom scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xaJJg-Ete7w"
      },
      "source": [
        "!git clone https://github.com/AGiannoutsos/End-to-End-Lane-Detection\n",
        "%cd End-to-End-Lane-Detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyUzlPS9TrHk"
      },
      "source": [
        "## Weights and biases initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxY32OCuTvTp"
      },
      "source": [
        "import wandb\n",
        "os.environ[\"WANDB_ENTITY\"]  = \"andreas_giannoutsos\"\n",
        "os.environ[\"WANDB_PROJECT\"] = \"lane_detection\"\n",
        "os.environ[\"WANDB_RESUME\"]  = \"allow\"\n",
        "from scripts.wandb_util import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AZCJMlgpVGr"
      },
      "source": [
        "## Dataset api from the stored files in the hardrive to arrays with label images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITtqPEEWYGyO"
      },
      "source": [
        "from scripts.dataset import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfF9bqvkpiST"
      },
      "source": [
        "## Fuctions that store a video clip from the given images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ELMUleagdB5"
      },
      "source": [
        "from scripts.visualization import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR7H7QmnNa6B"
      },
      "source": [
        "## Download, load, transform and save data images (done once)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tZPKzpnBkEjD"
      },
      "source": [
        "# Download TUsimple dataset\n",
        "download_TUsimple_dataset(\"train\")\n",
        "\n",
        "# Load and transform images and labels for classic lane detector\n",
        "train_dataset = Dataset(\"train_set\", (128,128))\n",
        "\n",
        "# Load, transform and save the dataset optimized for pytroch models\n",
        "pytorch_train_dataset = Pytorch_Dataset(\"pytorch_train_set\", train_dataset)\n",
        "\n",
        "# Upload dataset to weighs and biases cloud as an artifact so that we wont need to make these transforms again\n",
        "wandb_log_artifact(artifact_name=\"tusimple_train_set_1x128x128\", directory=\"pytorch_train_set\", type_=\"dataset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pV8_BzWlpLd"
      },
      "source": [
        "## Download transformed data from cloud and make sampler for train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0btDxgzHbyDa"
      },
      "source": [
        "# Load dataset as artifact from weights and biases\n",
        "os.environ[\"WANDB_ENTITY\"]  = \"andreas_giannoutsos\"\n",
        "os.environ[\"WANDB_PROJECT\"] = \"lane_detection\"\n",
        "os.environ[\"WANDB_RESUME\"]  = \"allow\"\n",
        "artifact_directory = wandb_load_artifact(artifact_name=\"tusimple_train_set_1x128x128\", version=\"latest\")\n",
        "\n",
        "# Load data optimized for pytorch models\n",
        "pytorch_train_dataset = Pytorch_Dataset(artifact_directory)\n",
        "\n",
        "# set a sampler for train and validation dataset\n",
        "# first 10% of training set will be validation set\n",
        "split = int(len(pytorch_train_dataset)*0.1)\n",
        "indices = list(range(len(pytorch_train_dataset)))\n",
        "np.random.shuffle(indices)\n",
        "train_sampler      = torch.utils.data.sampler.SubsetRandomSampler(indices[split:])\n",
        "validation_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices[0:split])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brOupfLbWyQ6"
      },
      "source": [
        "## Autoencoder model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv9jfbXyEBTA",
        "outputId": "126535ff-7c8b-4ff3-8116-ea20ecfe95b6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMyh5iAoEfj8"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, module):\n",
        "        super(Model, self).__init__()\n",
        "        self.module = module\n",
        "    \n",
        "    def get_output(self, image):\n",
        "        with torch.no_grad():\n",
        "            output = self(image.unsqueeze(0)).cpu()\n",
        "            return torch_model_to_cv2(output[0])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.module(x)              \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N7etXQRS2t_"
      },
      "source": [
        "## Train methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOAWphlcKaXB"
      },
      "source": [
        "from scripts.train_methods import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owt-h0usSrUE"
      },
      "source": [
        "## Simple vanilla Auto-Encoder 0.5M parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFiFICPJSq0N"
      },
      "source": [
        "class Config(object):\n",
        "    def __init__(self):\n",
        "        # parameters\n",
        "        self.learning_rate   = 1e-3\n",
        "        self.dropout         = 0\n",
        "        self.weight_decay    = 0.0\n",
        "        self.gradient_clip   = 1\n",
        "        self.batch_size      = 32\n",
        "        self.val_batch_size  = 32\n",
        "        self.epochs          = 1\n",
        "        self.loss            = nn.BCELoss()\n",
        "    \n",
        "WANDB_ID            = \"simple_autoencoder_t3\"\n",
        "WNDB_NAME           = \"simple_autoencoder_t3\"\n",
        "LOAD_SAVED_MODEL    = False\n",
        "LOG_INTERVAL        = 5\n",
        "MODEL_SAVE_NAME     = \"simple_autoencoder_t3\"\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "\n",
        "config = Config()\n",
        "train_dataloader      = DataLoader(pytorch_train_dataset, batch_size=config.batch_size, pin_memory=True, num_workers=1, drop_last=True, sampler=train_sampler)\n",
        "validation_dataloader = DataLoader(pytorch_train_dataset, batch_size=config.val_batch_size, pin_memory=True, num_workers=1, drop_last=True, sampler=validation_sampler)\n",
        "\n",
        "SimpleAutoEncoder = nn.Sequential(\n",
        "          nn.Conv2d(1, 8, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(8),\n",
        "          nn.Conv2d(8, 16, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.MaxPool2d(2, 2),\n",
        "\n",
        "          nn.Conv2d(16, 32, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.Conv2d(32, 64, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.MaxPool2d(2, 2),\n",
        "\n",
        "          nn.Conv2d(64, 128, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.Conv2d(128, 128, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.MaxPool2d(2, 2),\n",
        "\n",
        "          nn.Conv2d(128, 128, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(128, 64, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "\n",
        "          nn.Conv2d(64, 32, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(32, 16, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "\n",
        "          nn.Conv2d(16, 8, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(8, 1, 3, padding=1),\n",
        "          nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "          nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "if ('model' not in globals()) and (LOAD_SAVED_MODEL is False): # not reinitializing the model or the optimizer\n",
        "    print(\"INITIALIZE NEW MODEL\")\n",
        "    model = Model(SimpleAutoEncoder).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay) # optimizer\n",
        "\n",
        "elif LOAD_SAVED_MODEL is True: # load model from cloud\n",
        "    try:\n",
        "        print(\"LOAD SAVED MODEL\")\n",
        "        model_artifact_directory = wandb_load_artifact(run, MODEL_SAVE_NAME, SAVED_MODEL_VERSION)\n",
        "        # load model, history, optimizer\n",
        "        checkpoint = torch.load(os.path.join(model_artifact_directory,MODEL_SAVE_NAME))\n",
        "        initial_epoch = checkpoint[\"initial_epoch\"]\n",
        "        history = checkpoint[\"history\"]\n",
        "        model = checkpoint[\"model\"].to(device)\n",
        "        optimizer = checkpoint['optimizer_state_dict']\n",
        "    except:\n",
        "        print(\"NO MODEL FOUND\")\n",
        "\n",
        "\n",
        "run = wandb.init(config=config.__dict__, resume=WANDB_ID)  \n",
        "run.name = WNDB_NAME\n",
        "\n",
        "\n",
        "history = train_model(model, optimizer, config.loss, config, train_dataloader, validation_dataloader, device, checkpoint_path=MODEL_SAVE_NAME, run=run, log_interval=LOG_INTERVAL, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29oSnOOvTqJ-"
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fdyVIf7hiDW"
      },
      "source": [
        "## Unet + ResNet34 21M parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpxFydZbOsRS"
      },
      "source": [
        "class Config(object):\n",
        "    def __init__(self):\n",
        "        # parameters\n",
        "        self.learning_rate   = 1e-4\n",
        "        self.dropout         = 0\n",
        "        self.weight_decay    = 0.0\n",
        "        self.gradient_clip   = 1\n",
        "        self.batch_size      = 32\n",
        "        self.val_batch_size  = 32\n",
        "        self.epochs          = 5\n",
        "        self.loss            = nn.BCELoss()\n",
        "    \n",
        "WANDB_ID            = \"unet_resnet34_t3\"\n",
        "WNDB_NAME           = \"unet_resnet34_t3\"\n",
        "LOAD_SAVED_MODEL    = True\n",
        "LOG_INTERVAL        = 5\n",
        "MODEL_SAVE_NAME     = \"unet_resnet34_t3\"\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "\n",
        "config = Config()\n",
        "train_dataloader      = DataLoader(pytorch_train_dataset, batch_size=config.batch_size, pin_memory=True, num_workers=1, drop_last=True, sampler=train_sampler)\n",
        "validation_dataloader = DataLoader(pytorch_train_dataset, batch_size=config.val_batch_size, pin_memory=True, num_workers=1, drop_last=True, sampler=validation_sampler)\n",
        "\n",
        "if ('model' not in globals()) and (LOAD_SAVED_MODEL is False): # not reinitializing the model or the optimizer\n",
        "    print(\"INITIALIZE NEW MODEL\")\n",
        "    model = Model(smp.Unet(encoder_name='resnet34',\n",
        "                            encoder_depth=5,\n",
        "                            encoder_weights='imagenet',\n",
        "                            decoder_use_batchnorm=True,\n",
        "                            decoder_channels=(256, 128, 64, 32, 16),\n",
        "                            decoder_attention_type=None,\n",
        "                            in_channels=1,\n",
        "                            classes=1,\n",
        "                            activation=\"sigmoid\",\n",
        "                            aux_params=None)\n",
        "                ).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay) # optimizer\n",
        "\n",
        "elif LOAD_SAVED_MODEL is True: # load model from cloud\n",
        "    try:\n",
        "        print(\"LOAD SAVED MODEL\")\n",
        "        model_artifact_directory = wandb_load_artifact(run, MODEL_SAVE_NAME, SAVED_MODEL_VERSION)\n",
        "        # load model, history, optimizer\n",
        "        checkpoint = torch.load(os.path.join(model_artifact_directory,MODEL_SAVE_NAME))\n",
        "        initial_epoch = checkpoint[\"initial_epoch\"]\n",
        "        history = checkpoint[\"history\"]\n",
        "        model = checkpoint[\"model\"].to(device)\n",
        "        optimizer = checkpoint['optimizer_state_dict']\n",
        "    except:\n",
        "        print(\"NO MODEL FOUND\")\n",
        "\n",
        "\n",
        "run = wandb.init(config=config.__dict__, resume=WANDB_ID)  \n",
        "run.name = WNDB_NAME\n",
        "\n",
        "\n",
        "history = train_model(model, optimizer, config.loss, config, train_dataloader, validation_dataloader, device, checkpoint_path=MODEL_SAVE_NAME, run=run, log_interval=LOG_INTERVAL, verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfAfrK-mDb_P"
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EemFGYo6BbPB"
      },
      "source": [
        "## Unet + MobileNetV2 2M parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUSabPARBaLV"
      },
      "source": [
        "class Config(object):\n",
        "    def __init__(self):\n",
        "        # parameters\n",
        "        self.learning_rate   = 1e-4\n",
        "        self.dropout         = 0\n",
        "        self.weight_decay    = 0.0\n",
        "        self.gradient_clip   = 1\n",
        "        self.batch_size      = 32\n",
        "        self.val_batch_size  = 32\n",
        "        self.epochs          = 3\n",
        "        self.loss            = nn.BCELoss()\n",
        "    \n",
        "WANDB_ID            = \"unet_mobilenetv2_t1\"\n",
        "WNDB_NAME           = \"unet_mobilenetv2_t1\"\n",
        "LOAD_SAVED_MODEL    = True\n",
        "LOG_INTERVAL        = 5\n",
        "MODEL_SAVE_NAME     = \"unet_mobilenetv2_t1\"\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "\n",
        "config = Config()\n",
        "train_dataloader      = DataLoader(pytorch_train_dataset, batch_size=config.batch_size, pin_memory=True, num_workers=1, drop_last=True, sampler=train_sampler)\n",
        "validation_dataloader = DataLoader(pytorch_train_dataset, batch_size=config.val_batch_size, pin_memory=True, num_workers=1, drop_last=True, sampler=validation_sampler)\n",
        "\n",
        "if ('model' not in globals()) and (LOAD_SAVED_MODEL is False): # not reinitializing the model or the optimizer\n",
        "    print(\"INITIALIZE NEW MODEL\")\n",
        "    model = Model(smp.Unet(encoder_name='mobilenet_v2',\n",
        "                            encoder_depth=5,\n",
        "                            encoder_weights='imagenet',\n",
        "                            decoder_use_batchnorm=True,\n",
        "                            decoder_channels=(256, 128, 64, 32, 16),\n",
        "                            decoder_attention_type=None,\n",
        "                            in_channels=1,\n",
        "                            classes=1,\n",
        "                            activation=\"sigmoid\",\n",
        "                            aux_params=None)\n",
        "                ).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay) # optimizer\n",
        "\n",
        "elif LOAD_SAVED_MODEL is True: # load model from cloud\n",
        "    try:\n",
        "        print(\"LOAD SAVED MODEL\")\n",
        "        model_artifact_directory = wandb_load_artifact(run, MODEL_SAVE_NAME, SAVED_MODEL_VERSION)\n",
        "        # load model, history, optimizer\n",
        "        checkpoint = torch.load(os.path.join(model_artifact_directory,MODEL_SAVE_NAME))\n",
        "        initial_epoch = checkpoint[\"initial_epoch\"]\n",
        "        history = checkpoint[\"history\"]\n",
        "        model = checkpoint[\"model\"].to(device)\n",
        "        optimizer = checkpoint['optimizer_state_dict']\n",
        "    except:\n",
        "        print(\"NO MODEL FOUND\")\n",
        "\n",
        "\n",
        "run = wandb.init(config=config.__dict__, resume=WANDB_ID)  \n",
        "run.name = WNDB_NAME\n",
        "\n",
        "\n",
        "history = train_model(model, optimizer, config.loss, config, train_dataloader, validation_dataloader, device, checkpoint_path=MODEL_SAVE_NAME, run=run, log_interval=LOG_INTERVAL, verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD4GaVPvDc2N"
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX8PF58jBztd"
      },
      "source": [
        "## Unet + EfficientNet 6M parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJbEbCAFCLKy"
      },
      "source": [
        "class Config(object):\n",
        "    def __init__(self):\n",
        "        # parameters\n",
        "        self.learning_rate   = 1e-4\n",
        "        self.dropout         = 0\n",
        "        self.weight_decay    = 0.0\n",
        "        self.gradient_clip   = 1\n",
        "        self.batch_size      = 32\n",
        "        self.val_batch_size  = 32\n",
        "        self.epochs          = 7\n",
        "        self.loss            = nn.BCELoss()\n",
        "    \n",
        "WANDB_ID            = \"unet_efficentnet_t1\"\n",
        "WNDB_NAME           = \"unet_efficentnet_t1\"\n",
        "LOAD_SAVED_MODEL    = True\n",
        "LOG_INTERVAL        = 5\n",
        "MODEL_SAVE_NAME     = \"unet_efficentnet_t1\"\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "\n",
        "config = Config()\n",
        "train_dataloader      = DataLoader(pytorch_train_dataset, batch_size=config.batch_size, pin_memory=True, num_workers=1, drop_last=True, sampler=train_sampler)\n",
        "validation_dataloader = DataLoader(pytorch_train_dataset, batch_size=config.val_batch_size, pin_memory=True, num_workers=1, drop_last=True, sampler=validation_sampler)\n",
        "\n",
        "if ('model' not in globals()) and (LOAD_SAVED_MODEL is False): # not reinitializing the model or the optimizer\n",
        "    print(\"INITIALIZE NEW MODEL\")\n",
        "    model = Model(smp.Unet(encoder_name='efficientnet-b1',\n",
        "                            encoder_depth=5,\n",
        "                            encoder_weights='imagenet',\n",
        "                            decoder_use_batchnorm=True,\n",
        "                            decoder_channels=(256, 128, 64, 32, 16),\n",
        "                            decoder_attention_type=None,\n",
        "                            in_channels=1,\n",
        "                            classes=1,\n",
        "                            activation=\"sigmoid\",\n",
        "                            aux_params=None)\n",
        "                ).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay) # optimizer\n",
        "\n",
        "elif LOAD_SAVED_MODEL is True: # load model from cloud\n",
        "    try:\n",
        "        print(\"LOAD SAVED MODEL\")\n",
        "        model_artifact_directory = wandb_load_artifact(run, MODEL_SAVE_NAME, SAVED_MODEL_VERSION)\n",
        "        # load model, history, optimizer\n",
        "        checkpoint = torch.load(os.path.join(model_artifact_directory,MODEL_SAVE_NAME))\n",
        "        initial_epoch = checkpoint[\"initial_epoch\"]\n",
        "        history = checkpoint[\"history\"]\n",
        "        model = checkpoint[\"model\"].to(device)\n",
        "        optimizer = checkpoint['optimizer_state_dict']\n",
        "    except:\n",
        "        print(\"NO MODEL FOUND\")\n",
        "\n",
        "\n",
        "run = wandb.init(config=config.__dict__, resume=WANDB_ID)  \n",
        "run.name = WNDB_NAME\n",
        "\n",
        "\n",
        "history = train_model(model, optimizer, config.loss, config, train_dataloader, validation_dataloader, device, checkpoint_path=MODEL_SAVE_NAME, run=run, log_interval=LOG_INTERVAL, verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLxidTcqDd0h"
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuGBKYsfkg-D"
      },
      "source": [
        "autoencoder_visualization([history], pytorch_train_dataset, model, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpH127nKPvPV",
        "outputId": "ef4b6c53-82f7-4e15-f7fe-2417a62ede84"
      },
      "source": [
        "# pytorch_train_dataset[0][0]\n",
        "# model(pytorch_train_dataset[0][0].unsqueeze(0))\n",
        "# pytorch_train_dataset[0][1].max()\n",
        "import pandas as pd\n",
        "# out.mean()\n",
        "df = pd.DataFrame(out.ravel())\n",
        "df.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      49104\n",
              "1         36\n",
              "255       12\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RulevACDBPky"
      },
      "source": [
        "# a = torch.where(pytorch_train_dataset[0][1] > pytorch_train_dataset[0][1].mean(), 1.0, 0.0)\n",
        "# a.max()\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH6s1D4Mw0M-"
      },
      "source": [
        "# for data, labels in train_dataloader:\n",
        "#     out = model(data)\n",
        "#     break\n",
        "\n",
        "i = 15090\n",
        "out = 0\n",
        "# with torch.no_grad():\n",
        "    # model.eval()\n",
        "out = model.get_output(pytorch_train_dataset[i][0].to(device))\n",
        "out = np.where(out > out.mean(), 255,1)\n",
        "\n",
        "cv2_imshow(out)\n",
        "# cv2_imshow(cv2.resize(out, (256,256)))\n",
        "# cv2_imshow(cv2.resize(train_dataset[i][0], (256,256)))\n",
        "cv2_imshow(cv2.resize(torch_model_to_cv2(pytorch_train_dataset[i][0]), (256,256)))\n",
        "cv2_imshow(cv2.resize(torch_model_to_cv2(pytorch_train_dataset[i][1]), (256,256)))\n",
        "cv2_imshow(cv2.resize(torch_model_to_cv2(a), (256,256)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VINAVSUON7ip"
      },
      "source": [
        "torch_video_detector_creator(\"model\", model, train_dataset, pytorch_train_dataset, 0, 99, True, fps=24)\n",
        "# video_detector_creator(\"model\", detector, train_dataset, 0, 99, True, fps=24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuDZXUoSN7it"
      },
      "source": [
        "from moviepy.editor import *\n",
        "path = \"model.avi\" \n",
        "clip=VideoFileClip(path)\n",
        "clip.ipython_display(width=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCIlLU2lgt8_"
      },
      "source": [
        "## Results get the detectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSYo9FMAg1TW"
      },
      "source": [
        "MODEL_SAVE_NAME     = \"simple_autoencoder_t2\"\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "model_artifact_directory = wandb_load_artifact(run, MODEL_SAVE_NAME, SAVED_MODEL_VERSION)\n",
        "checkpoint = torch.load(os.path.join(model_artifact_directory,MODEL_SAVE_NAME))\n",
        "simple_autoencoder_model = checkpoint[\"model\"].to(device)\n",
        "\n",
        "MODEL_SAVE_NAME     = \"unet_resnet34_t3\"\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "model_artifact_directory = wandb_load_artifact(run, MODEL_SAVE_NAME, SAVED_MODEL_VERSION)\n",
        "checkpoint = torch.load(os.path.join(model_artifact_directory,MODEL_SAVE_NAME))\n",
        "resNet34_model = checkpoint[\"model\"].to(device)\n",
        "\n",
        "MODEL_SAVE_NAME     = \"unet_mobilenetv2_t1\"\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "model_artifact_directory = wandb_load_artifact(run, MODEL_SAVE_NAME, SAVED_MODEL_VERSION)\n",
        "checkpoint = torch.load(os.path.join(model_artifact_directory,MODEL_SAVE_NAME))\n",
        "mobileNetV2_model = checkpoint[\"model\"].to(device)\n",
        "\n",
        "MODEL_SAVE_NAME     = \"unet_efficentnet_t1\"\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "model_artifact_directory = wandb_load_artifact(run, MODEL_SAVE_NAME, SAVED_MODEL_VERSION)\n",
        "checkpoint = torch.load(os.path.join(model_artifact_directory,MODEL_SAVE_NAME))\n",
        "efficientNet_model = checkpoint[\"model\"].to(device)\n",
        "\n",
        "detectors = [simple_autoencoder_model,\n",
        "             resNet34_model,\n",
        "             mobileNetV2_model,\n",
        "             efficientNet_model]\n",
        "texts =     [\"Simple AE 0.5M\",\n",
        "             \"ResNet 21M\",\n",
        "             \"MobileNet 2M\",\n",
        "             \"EfficientNet 6M\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9XfvA4WlqV7"
      },
      "source": [
        "## Create grid videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE5Nm-tEl7v5"
      },
      "source": [
        "torch_grid_video_detector_creator(\"video_AEmodels_grid\",\n",
        "                  detectors,\n",
        "                  texts,\n",
        "                  pytorch_train_dataset, \n",
        "                  70000, \n",
        "                  2000,\n",
        "                  grid=(2,2), \n",
        "                  labels=False, \n",
        "                  fps=24, \n",
        "                  overlay_opacity=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyUWrP4OTauc"
      },
      "source": [
        "## Create grid images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caY1tiFbNr3r"
      },
      "source": [
        "for i in range(10):\n",
        "    torch_grid_image_detector_creator(\"image\"+str(i)+\"_AEmodels_grid.jpg\",\n",
        "                  detectors,\n",
        "                  texts,\n",
        "                  pytorch_train_dataset, \n",
        "                  np.random.randint(len(pytorch_train_dataset)), \n",
        "                  grid=(2,2), \n",
        "                  labels=False, \n",
        "                  fps=24, \n",
        "                  overlay_opacity=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0drto3ilqvgW"
      },
      "source": [
        "from moviepy.editor import *\n",
        "path = \"video_AEmodels_grid.avi\" \n",
        "clip=VideoFileClip(path)\n",
        "clip.ipython_display(width=512)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}